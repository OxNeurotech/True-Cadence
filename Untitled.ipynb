{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3fdecd0-3f02-471e-af36-ce283ed3e01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Tuple\n",
    "import json\n",
    "import os\n",
    "from scipy.optimize import differential_evolution\n",
    "from scipy.stats import trim_mean\n",
    "import glob\n",
    "from fuzzy_controller import TrainableFuzzyController\n",
    "import argparse\n",
    "\n",
    "class FuzzyControllerTrainer:\n",
    "    def __init__(self, training_data_dir: str):\n",
    "        \"\"\"\n",
    "        Initialize trainer with data from both high and low cognitive load states\n",
    "        \n",
    "        Args:\n",
    "            training_data_dir: Directory containing the training data CSV files\n",
    "        \"\"\"\n",
    "        self.data = self._load_training_data(training_data_dir)\n",
    "        self.controller = TrainableFuzzyController()\n",
    "    \n",
    "    def _load_training_data(self, data_dir: str) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"Load and preprocess all training data\"\"\"\n",
    "        # Find the most recent files for each type\n",
    "        files = glob.glob(os.path.join(data_dir, '*.csv'))\n",
    "        if not files:\n",
    "            raise ValueError(f\"No CSV files found in {data_dir}\")\n",
    "            \n",
    "        latest_files = {\n",
    "            'baseline': None,\n",
    "            'high_load': None,\n",
    "            'low_load': None\n",
    "        }\n",
    "        \n",
    "        # Find the most recent file for each type\n",
    "        for file in files:\n",
    "            basename = os.path.basename(file)\n",
    "            for data_type in latest_files.keys():\n",
    "                if data_type in basename:\n",
    "                    if latest_files[data_type] is None or os.path.getmtime(file) > os.path.getmtime(latest_files[data_type]):\n",
    "                        latest_files[data_type] = file\n",
    "        \n",
    "        # Load and preprocess each dataset\n",
    "        datasets = {}\n",
    "        for data_type, filepath in latest_files.items():\n",
    "            if filepath and os.path.exists(filepath):\n",
    "                print(f\"Loading {data_type} data from {filepath}\")\n",
    "                df = pd.read_csv(filepath)\n",
    "                df = self._preprocess_data(df)\n",
    "                datasets[data_type] = df\n",
    "            else:\n",
    "                print(f\"Warning: No data found for {data_type}\")\n",
    "        \n",
    "        return datasets\n",
    "    \n",
    "    def _preprocess_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Preprocess data to remove outliers and normalize values\"\"\"\n",
    "        processed_df = df.copy()\n",
    "        \n",
    "        # Remove outliers using IQR method\n",
    "        for col in ['Theta_pow', 'Alpha_pow', 'Beta_pow', 'Gamma_pow']:\n",
    "            if col in processed_df.columns:\n",
    "                Q1 = processed_df[col].quantile(0.25)\n",
    "                Q3 = processed_df[col].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                processed_df = processed_df[\n",
    "                    (processed_df[col] >= Q1 - 1.5 * IQR) & \n",
    "                    (processed_df[col] <= Q3 + 1.5 * IQR)\n",
    "                ]\n",
    "        \n",
    "        return processed_df\n",
    "    \n",
    "    def _calculate_ideal_speed(self, cognitive_load: float, data_type: str) -> float:\n",
    "        \"\"\"\n",
    "        Calculate ideal speed based on cognitive load and data type\n",
    "        \n",
    "        Args:\n",
    "            cognitive_load: Beta/(Theta + Alpha) ratio\n",
    "            data_type: 'baseline', 'high_load', or 'low_load'\n",
    "        \"\"\"\n",
    "        if data_type == 'high_load':\n",
    "            # Slower speeds for high cognitive load\n",
    "            base_speed = 1.5\n",
    "            min_speed = 0.75\n",
    "            midpoint = 0.7\n",
    "        elif data_type == 'low_load':\n",
    "            # Faster speeds for low cognitive load\n",
    "            base_speed = 2.5\n",
    "            min_speed = 1.5\n",
    "            midpoint = 0.4\n",
    "        else:  # baseline\n",
    "            # Medium speeds for baseline\n",
    "            base_speed = 2.0\n",
    "            min_speed = 1.0\n",
    "            midpoint = 0.5\n",
    "        \n",
    "        steepness = 5\n",
    "        speed = base_speed - (base_speed - min_speed) / (\n",
    "            1 + np.exp(-steepness * (cognitive_load - midpoint))\n",
    "        )\n",
    "        return np.clip(speed, self.controller.config.min_speed, \n",
    "                      self.controller.config.max_speed)\n",
    "    \n",
    "    def objective_function(self, params):\n",
    "        \"\"\"Objective function that considers all states\"\"\"\n",
    "        # Unpack parameters\n",
    "        speed_rules = {\n",
    "            'very_low':  params[0],\n",
    "            'low':       params[1],\n",
    "            'medium':    params[2],\n",
    "            'high':      params[3],\n",
    "            'very_high': params[4]\n",
    "        }\n",
    "        beta_weight = params[5]\n",
    "        beta_spread = params[6]\n",
    "        ratio_spread = params[7]\n",
    "        \n",
    "        # Update controller parameters\n",
    "        self.controller.params.speed_rules = speed_rules\n",
    "        self.controller.params.beta_weight = beta_weight\n",
    "        self.controller.params.ratio_weight = 1 - beta_weight\n",
    "        self.controller.params.beta_spread = beta_spread\n",
    "        self.controller.params.ratio_spread = ratio_spread\n",
    "        \n",
    "        total_error = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        # Calculate error for each dataset\n",
    "        for data_type, df in self.data.items():\n",
    "            if df is None or df.empty:\n",
    "                continue\n",
    "                \n",
    "            for _, row in df.iterrows():\n",
    "                target_speed = self.controller.update(\n",
    "                    row['Theta_pow'],\n",
    "                    row['Alpha_pow'],\n",
    "                    row['Beta_pow']\n",
    "                )\n",
    "                \n",
    "                beta_ratio = row['Beta_pow'] / (row['Theta_pow'] + row['Alpha_pow'])\n",
    "                ideal_speed = self._calculate_ideal_speed(beta_ratio, data_type)\n",
    "                \n",
    "                # Calculate weighted error\n",
    "                error = (target_speed - ideal_speed) ** 2\n",
    "                \n",
    "                # Add higher penalty for deviations in high cognitive load state\n",
    "                if data_type == 'high_load':\n",
    "                    error *= 1.5\n",
    "                \n",
    "                total_error += error\n",
    "                total_samples += 1\n",
    "        \n",
    "        return total_error / total_samples if total_samples > 0 else float('inf')\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Train the controller using all available data\"\"\"\n",
    "        bounds = [\n",
    "            (1.5, 2.5),   # very_low speed\n",
    "            (1.25, 2.0),  # low speed\n",
    "            (0.9, 1.1),   # medium speed\n",
    "            (0.5, 0.8),   # high speed\n",
    "            (0.3, 0.6),   # very_high speed\n",
    "            (0.5, 0.8),   # beta_weight\n",
    "            (0.5, 1.5),   # beta_spread\n",
    "            (0.1, 0.3)    # ratio_spread\n",
    "        ]\n",
    "        \n",
    "        result = differential_evolution(\n",
    "            self.objective_function,\n",
    "            bounds,\n",
    "            maxiter=50,\n",
    "            popsize=20,\n",
    "            tol=0.01,\n",
    "            mutation=(0.5, 1.0),\n",
    "            recombination=0.7,\n",
    "            updating='deferred',\n",
    "            workers=-1  # Use all available CPU cores\n",
    "        )\n",
    "        \n",
    "        if result.success:\n",
    "            print(\"\\nTraining successful!\")\n",
    "            print(f\"Final error: {result.fun:.6f}\")\n",
    "            \n",
    "            # Update controller with optimal parameters\n",
    "            optimal_params = result.x\n",
    "            self.controller.params.speed_rules = {\n",
    "                'very_low':  optimal_params[0],\n",
    "                'low':       optimal_params[1],\n",
    "                'medium':    optimal_params[2],\n",
    "                'high':      optimal_params[3],\n",
    "                'very_high': optimal_params[4]\n",
    "            }\n",
    "            self.controller.params.beta_weight = optimal_params[5]\n",
    "            self.controller.params.ratio_weight = 1 - optimal_params[5]\n",
    "            self.controller.params.beta_spread = optimal_params[6]\n",
    "            self.controller.params.ratio_spread = optimal_params[7]\n",
    "            \n",
    "            print(\"\\nOptimized Parameters:\")\n",
    "            print(f\"Speed Rules: {self.controller.params.speed_rules}\")\n",
    "            print(f\"Beta Weight: {self.controller.params.beta_weight:.2f}\")\n",
    "            print(f\"Ratio Weight: {self.controller.params.ratio_weight:.2f}\")\n",
    "            print(f\"Beta Spread: {self.controller.params.beta_spread:.2f}\")\n",
    "            print(f\"Ratio Spread: {self.controller.params.ratio_spread:.2f}\")\n",
    "        else:\n",
    "            print(\"\\nTraining failed:\", result.message)\n",
    "        \n",
    "        return self.controller\n",
    "\n",
    "def train_controller(training_data_dir: str, output_params_path: str):\n",
    "    \"\"\"\n",
    "    Train controller using all available data and save parameters\n",
    "    \n",
    "    Args:\n",
    "        training_data_dir: Directory containing training data CSV files\n",
    "        output_params_path: Path to save optimized parameters JSON\n",
    "    \"\"\"\n",
    "    print(f\"\\nStarting controller training...\")\n",
    "    print(f\"Loading data from: {training_data_dir}\")\n",
    "    print(f\"Parameters will be saved to: {output_params_path}\")\n",
    "    \n",
    "    trainer = FuzzyControllerTrainer(training_data_dir)\n",
    "    trained_controller = trainer.train()\n",
    "    \n",
    "    if trained_controller is not None:\n",
    "        params_dict = {\n",
    "            'beta_centers': trained_controller.params.beta_centers,\n",
    "            'ratio_centers': trained_controller.params.ratio_centers,\n",
    "            'speed_rules': trained_controller.params.speed_rules,\n",
    "            'beta_weight': trained_controller.params.beta_weight,\n",
    "            'ratio_weight': trained_controller.params.ratio_weight,\n",
    "            'beta_spread': trained_controller.params.beta_spread,\n",
    "            'ratio_spread': trained_controller.params.ratio_spread\n",
    "        }\n",
    "        \n",
    "        # Just write directly to the file - no need for makedirs() if it's just a filename\n",
    "        with open(output_params_path, 'w') as f:\n",
    "            json.dump(params_dict, f, indent=4)\n",
    "        print(f\"\\nOptimized parameters saved to: {output_params_path}\")\n",
    "    \n",
    "    return trained_controller\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ad3e20f-5c8b-40eb-bd59-ae132d33f645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--data_dir DATA_DIR] [--output OUTPUT]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\10910\\AppData\\Roaming\\jupyter\\runtime\\kernel-985a4554-b1a9-4fb4-905c-eb4018720582.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Train Fuzzy Controller from collected EEG data')\n",
    "parser.add_argument('--data_dir', type=str, default='training_data',\n",
    "                  help='Directory containing training data CSV files')\n",
    "parser.add_argument('--output', type=str, default='optimized_parameters.json',\n",
    "                  help='Output path for optimized parameters JSON')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "try:\n",
    "    trained_controller = train_controller(\n",
    "        args.data_dir,\n",
    "        args.output\n",
    "    )\n",
    "    print(\"\\nTraining completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError during training: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba3c8aa-6ef3-4bde-9c3d-853ad862b45f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
